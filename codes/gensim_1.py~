#### This code finds the similarity between the the given query and the documents (list of sentences) and gives the output in descending order


from gensim import corpora,models,similarities
from collections import defaultdict

documents = ['car insurance','car insurance coverage',
'auto insurance','best insurance','how much is the car insurance','best auto coverage','auto policy','car policy insurance']

from nltk.corpus import stopwords
from nltk import download

download('stopwords')

stop_words = ([set(stopwords.words('english'))])
#print("\n stop_words => ",stop_words)

texts = [[ word.lower() for word in document.split()
	   if word.lower() not in stop_words]
	   for document in documents]

print("\n text => ",texts)

freq = defaultdict(int)
print("\n freq => ",freq)

for text in texts:
	print("\n text => ",text)
	for token in text: 
		print("\n token => ",token)
		freq[token] += 1


texts = [[token for token in text if freq[token] > 1]
	for text in texts]

print("\n texts => ",texts)

dictionary = corpora.Dictionary(texts)
print("\n dictionary => ",dictionary)

# doc2bow counts the number of occurences of each distinct word,
# converts the word to its integer word id and returns the result
# as a sparse vector
for text in texts:
	print("\n dictionary.doc2bow(text)",dictionary.doc2bow(text))

corpus = [dictionary.doc2bow(text) for text in texts] #### this is nothing but Document-Term-Matrix
print("\n corpus => ",corpus) 

#### processing user query

doc = "i want to buy a best car insurance."
vec_bow = dictionary.doc2bow(doc.lower().split())
print("\n dictionary.doc2bow(doc.lower().split()) => ",dictionary.doc2bow(doc.lower().split()))
print("\n vec_bow => ",vec_bow)

#### using LSI (latent semantic indexing ) model
#### link => http://stackoverflow.com/questions/31821821/semantic-similarity-between-phrases-using-gensim

lsi = models.LsiModel(corpus,id2word=dictionary,num_topics=3)

vec_lsi = lsi[vec_bow]
print("\nvec_lsi => ",vec_lsi)
index = similarities.MatrixSimilarity(lsi[corpus])
print("\n index => ",index)

sims = index[vec_lsi]
sims = sorted(enumerate(sims),key=lambda item: -item[1])

print("\n sims => ",sims)


#### using LDA ( Latent Dirichilet Alloation) model
#### link => https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/

import gensim

Lda = gensim.models.ldamodel.LdaModel

ldamodel = Lda(corpus, num_topics = 3, id2word = dictionary, passes = 50)
print(ldamodel.print_topics(num_topics = 3,num_words = 3))

vec_lda = ldamodel[vec_bow]
print("\n vec_lda => ",vec_lda)
index_1 = similarities.MatrixSimilarity(ldamodel[corpus])
print("\n index_1 => ",index_1)
sims_1 = index_1[vec_lda]
print("\n sim_1 => ",sims_1)
